name: Inference Pipeline

on:
  push:
    branches:
      - main
    paths:
      - 'data/**'
      - 'predict.py'
      - '.github/workflows/inference.yml'
  workflow_dispatch:
    inputs:
      data_file:
        description: 'Path to new data file (relative to repo root)'
        required: false
        default: 'data/new_data.csv'
        type: string

jobs:
  check-and-train:
    name: Check Model / Auto-Train if Needed
    runs-on: ubuntu-latest
    outputs:
      model_exists: ${{ steps.check.outputs.exists }}
      trained: ${{ steps.train.outputs.completed }}
    steps:
      - name: Check if model exists
        id: check
        continue-on-error: true
        uses: dawidd6/action-download-artifact@v3
        with:
          workflow: azureml.yml
          name: train-output
          path: model_check/
          search_artifacts: true
          workflow_conclusion: success

      - name: Set model existence flag
        id: set_flag
        run: |
          if [ "${{ steps.check.outcome }}" = "success" ] && [ -f model_check/model.pkl ]; then
            echo "exists=true" >> $GITHUB_OUTPUT
            echo "âœ… Model found - will proceed with inference"
          else
            echo "exists=false" >> $GITHUB_OUTPUT
            echo "âš ï¸ No model found - will trigger training pipeline first"
          fi

      - name: Trigger Training Pipeline
        id: train
        if: steps.set_flag.outputs.exists == 'false'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            console.log('ðŸš€ No trained model found. Triggering Training Pipeline...');
            
            // Trigger the training workflow
            const response = await github.rest.actions.createWorkflowDispatch({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: 'azureml.yml',
              ref: 'main',
              inputs: {
                retrain_reason: 'Auto-triggered by Inference Pipeline (no model found)'
              }
            });
            
            console.log('âœ… Training pipeline triggered successfully');
            console.log('â³ Waiting for training to complete...');
            
            // Wait a bit for the workflow to start
            await new Promise(resolve => setTimeout(resolve, 5000));
            
            // Poll for the workflow run to complete
            const maxAttempts = 60; // 10 minutes (60 * 10 seconds)
            let attempts = 0;
            let workflowRun = null;
            
            while (attempts < maxAttempts) {
              // Get recent workflow runs
              const runs = await github.rest.actions.listWorkflowRuns({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: 'azureml.yml',
                per_page: 5
              });
              
              // Find the most recent run that was triggered
              workflowRun = runs.data.workflow_runs.find(run => 
                run.status !== 'completed' || 
                (new Date(run.created_at) > new Date(Date.now() - 30000))
              );
              
              if (workflowRun && workflowRun.status === 'completed') {
                if (workflowRun.conclusion === 'success') {
                  console.log('âœ… Training pipeline completed successfully!');
                  core.setOutput('completed', 'true');
                  return;
                } else {
                  core.setFailed(`Training pipeline failed with conclusion: ${workflowRun.conclusion}`);
                  return;
                }
              }
              
              console.log(`â³ Still waiting... (attempt ${attempts + 1}/${maxAttempts})`);
              await new Promise(resolve => setTimeout(resolve, 10000)); // Wait 10 seconds
              attempts++;
            }
            
            core.setFailed('Training pipeline did not complete within the expected time');

      - name: Summary
        if: always()
        run: |
          echo "### Model Check Results" >> $GITHUB_STEP_SUMMARY
          if [ "${{ steps.set_flag.outputs.exists }}" = "true" ]; then
            echo "âœ… **Model found** - Proceeding with inference" >> $GITHUB_STEP_SUMMARY
          else
            echo "âš ï¸ **No model found** - Training pipeline was triggered" >> $GITHUB_STEP_SUMMARY
            if [ "${{ steps.train.outputs.completed }}" = "true" ]; then
              echo "âœ… **Training completed successfully** - Inference will now proceed" >> $GITHUB_STEP_SUMMARY
            else
              echo "âŒ **Training failed or timed out** - Inference cannot proceed" >> $GITHUB_STEP_SUMMARY
            fi
          fi

  prepare-inference-data:
    name: Prepare Raw Data
    runs-on: ubuntu-latest
    needs: check-and-train
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Determine input file
        id: input
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "file=${{ github.event.inputs.data_file }}" >> $GITHUB_OUTPUT
          else
            echo "file=data/new_data.csv" >> $GITHUB_OUTPUT
          fi

      - name: Validate and prepare data
        run: |
          python prepare_inference_data.py \
            --input "${{ steps.input.outputs.file }}" \
            --output outputs/inference_data

      - name: Upload cleaned data
        uses: actions/upload-artifact@v4
        with:
          name: inference-data
          path: outputs/inference_data/

  get-model:
    name: Get Trained Model
    runs-on: ubuntu-latest
    needs: [check-and-train, prepare-inference-data]
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Download latest model
        uses: dawidd6/action-download-artifact@v3
        with:
          workflow: azureml.yml
          name: train-output
          path: models/
          search_artifacts: true
          workflow_conclusion: success

      - name: Verify model
        run: |
          if [ ! -f "models/model.pkl" ]; then
            echo "[ERROR] Model file not found"
            exit 1
          fi
          echo "âœ… Model loaded successfully"
          ls -lh models/

      - name: Upload model
        uses: actions/upload-artifact@v4
        with:
          name: model
          path: models/

  predict:
    name: Make Predictions
    runs-on: ubuntu-latest
    needs: [prepare-inference-data, get-model]
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Download cleaned data
        uses: actions/download-artifact@v4
        with:
          name: inference-data
          path: outputs/inference_data/

      - name: Download model
        uses: actions/download-artifact@v4
        with:
          name: model
          path: models/

      - name: Run predictions
        run: |
          mkdir -p outputs/predictions
          python predict.py \
            --model models \
            --input outputs/inference_data/cleaned_data.csv \
            --output outputs/predictions

      - name: Upload predictions
        uses: actions/upload-artifact@v4
        with:
          name: predictions
          path: outputs/predictions/

  results:
    name: Summarize Results
    runs-on: ubuntu-latest
    needs: [prepare-inference-data, get-model, predict]
    if: always()
    steps:
      - name: Download all artifacts
        continue-on-error: true
        uses: actions/download-artifact@v4

      - name: Display results
        run: |
          if [ "${{ needs.get-model.result }}" != "success" ]; then
            echo "============================================================"
            echo "INFERENCE PIPELINE STOPPED"
            echo "============================================================"
            echo "Reason: No trained model found"
            echo ""
            echo "Next steps:"
            echo "1. Go to Actions > Training Pipeline"
            echo "2. Click 'Run workflow' to train a model"
            echo "3. After training completes, run this inference pipeline again"
            echo "============================================================"
          elif [ "${{ needs.predict.result }}" = "success" ]; then
            echo "[SUCCESS] Inference pipeline completed!"
            echo "=== Artifacts ==="
            ls -R
          else
            echo "[WARNING] Pipeline completed with issues"
            ls -R
          fi

      - name: Create summary
        run: |
          echo "## Inference Pipeline Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Run Number**: ${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ needs.check-and-train.outputs.model_exists }}" = "false" ]; then
            echo "### ðŸ”„ Auto-Training Triggered" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "No model was found, so the **Training Pipeline** was automatically triggered." >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            if [ "${{ needs.check-and-train.outputs.trained }}" = "true" ]; then
              echo "âœ… **Training completed successfully!** The newly trained model was used for inference." >> $GITHUB_STEP_SUMMARY
            else
              echo "âŒ **Training failed or timed out.** Inference could not proceed." >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "Please check the Training Pipeline run logs for details." >> $GITHUB_STEP_SUMMARY
            fi
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "${{ needs.get-model.result }}" != "success" ]; then
            echo "### Status: STOPPED" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "> **No trained model found!**" >> $GITHUB_STEP_SUMMARY
            echo ">" >> $GITHUB_STEP_SUMMARY
            echo "> Please run the **Training Pipeline** first:" >> $GITHUB_STEP_SUMMARY
            echo "> 1. Go to Actions tab" >> $GITHUB_STEP_SUMMARY
            echo "> 2. Select 'Training Pipeline'" >> $GITHUB_STEP_SUMMARY
            echo "> 3. Click 'Run workflow'" >> $GITHUB_STEP_SUMMARY
            echo "> 4. Wait for completion" >> $GITHUB_STEP_SUMMARY
            echo "> 5. Run inference pipeline again" >> $GITHUB_STEP_SUMMARY
          elif [ -f predictions/prediction_summary.json ]; then
            echo "### Status: SUCCESS" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Prediction Statistics" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`json" >> $GITHUB_STEP_SUMMARY
            cat predictions/prediction_summary.json >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Artifacts" >> $GITHUB_STEP_SUMMARY
            echo "- **inference-data**: Cleaned input data" >> $GITHUB_STEP_SUMMARY
            echo "- **model**: Trained model used for predictions" >> $GITHUB_STEP_SUMMARY
            echo "- **predictions**: Prediction results and statistics" >> $GITHUB_STEP_SUMMARY
          else
            echo "### Status: FAILED" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Check job logs for details" >> $GITHUB_STEP_SUMMARY
          fi
